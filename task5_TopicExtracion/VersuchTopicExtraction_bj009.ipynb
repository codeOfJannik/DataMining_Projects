{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Extraction in Newsfeeds\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 17.11.2015\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.ipynb)\n",
    "\n",
    "# Einführung\n",
    "## Lernziele:\n",
    "\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* __RSS Feeds:__ Struktur von RSS Feeds analysieren und parsen mit dem _Universal Feed Parser_. \n",
    "* __Dokument Analyse:__ Die Häufigkeit aller Worte in einem Dokument (Inhalt des RSS Feeds) zählen und in einem Array verwalten. \n",
    "* __Merkmalsextraktion:__ Bestimmung von Merkmalen (hier auch: __Topics__) (Allgemein spricht man von Merkmalen. Im Fall, dass die NNMF auf Dokumente angewandt wird, werden die Merkmale auch mit __Topics__ oder __Themen__ bezeichnet) mit der \\emph{Non Negative Matrix Factorization}.\n",
    "* __Zuordnung__: Wie setzen sich die Topics aus den Wörtern zusammen? Wie stark sind die gefundenen Topics in den Artikeln vertreten?\n",
    "* __Dokument Clustering:__ Mit der NNMF kann auch ein Clustering realisiert werden. Jeder Topic repräsentiert ein Cluster. Jedes Dokument wird dem Cluster zugeordnet, dessen Topic am stärksten in ihm vertreten ist. \n",
    "\n",
    "Sämtliche Verfahren und Algorithmen werden in Python implementiert.\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "\n",
    "Stellen Sie sich vor Sie möchten in eine eigene Webseite die RSS Feeds einer Menge von Nachrichtenservern einbinden. Da die unterschiedlichen Server wahrscheinlich Artikel zu den gleichen Themen anbieten, werden die Inhalte einiger Artikel ähnlich sein. Mit der __Nicht Negativen Matrixfaktorisierung (NNMF)__ kann für eine große Menge von Dokumenten eine Menge von Themen (Topics) ermittelt werden, auf die sich die Dokumente beziehen. Damit ist es u.a. möglich\n",
    "* die Dokumente thematisch zu ordnen\n",
    "* zu jedem Thema nur ein Dokument anzuzeigen\n",
    "\n",
    "### Ähnlichkeiten bestimmen und relevante Merkmale extrahieren\n",
    "\n",
    "Eine Sammlung von Dokumenten - in diesem Versuch die Menge aller Nachrichten der angegebenen Feeds - kann in einer Artikel/Wort-Matrix repräsentiert werden. Jede Zeile dieser Matrix gehört zu einem Dokument. Für jedes Wort, das mindestens in einem der Dokumente vorkommt, ist eine Spalte vorgesehen. Das Matrixelement in Zeile $i$, Spalte $j$ beschreibt wie häufig das Wort in Spalte $j$ im zur Zeile $i$ gehörenden Dokument vorkommt.\n",
    "\n",
    "Unter der Annahme, dass Artikel umso ähnlicher sind, je mehr Worte in diesen gemeinsam vorkommen, kann auf der Grundlage dieser Matrix die Ähnlichkeit zwischen den Artikeln berechnet werden. Hierzu könnte die Matrix z.B. einfach einem _Hierarchischen Clustering_ übergeben werden. Das hierarchische Clustering weist jedoch im Fall einer großen Menge von zu vergleichenden Objekten zwei wesentliche Nachteile auf: Erstens ist die wiederholte Berechnung der Distanzen zwischen allen Artikeln/Clustern extrem rechenaufwendig, zweitens ist die Darstellung einer großen Anzahl von Objekten im Dendrogramm nicht mehr übersichtlich. \n",
    "\n",
    "Für das Auffinden von Assoziationen zwischen Dokumenten hat sich in den letzten Jahren die Methode der __Nicht-Negativen Matrix Faktorisierung (NNMF)__ etabliert. Mit dieser Methode kann eine Menge von wesentlichen Merkmalen berechnet werden, anhand derer sich die Dokumente clustern lassen, d.h. Dokumente des gleichen Clusters repräsentieren das gleiche Merkmal (Thema). Ein solches Merkmal wird durch eine Menge von Worten beschrieben, z.B. $\\{$ _Paris, terror, IS_ $\\}$  oder $\\{$_refugee, syria, border_ $\\}$. Neben der Merkmalsextraktion stellt die relativ geringe Komplexität einen weiteren Vorteil der NNMF dar. Durch die Darstellung der Artikel/Wort-Matrix als Produkt von 2 Faktormatrizen müssen deutlich weniger Einträge gespeichert werden.\n",
    "\n",
    "### Nicht Negative Matrixfaktorisierung: Die Idee\n",
    "\n",
    "Die Artikel/Wort-Matrix wird im Folgenden mit $A$ bezeichnet. Sie besitzt $r$ Zeilen und $c$ Spalten, wobei $r$ die Anzahl der Artikel und $c$ die Anzahl der relevanten Worte in der Menge aller Artikel ist. Durch Multiplikation der Matrix $A$ mit dem Vektor $v$ (_wordvec_: Vektor der alle relevanten Worte enthält) werden die Worte den Artikeln $a$ (_articletitles_: Vektor der alle Artikeltitel enthält) zugeordnet:\n",
    "\n",
    "$$\n",
    "a=A*v.\n",
    "$$\n",
    "\n",
    "Die Idee der NNMF besteht darin die Matrix $A$ als Produkt zweier Matrizen $W$ und $H$ darzustellen,\n",
    "\n",
    "$$\n",
    "A=W*H\n",
    "$$\n",
    "\n",
    "wobei alle Elemente in $W$ und $H$ größer oder gleich Null sein müssen. Die Matrixmultiplikation erfordert, dass die Anzahl der Zeilen $m$ in $H$ gleich der Anzahl der Spalten in $W$ sein muss. \n",
    "Durch die Faktorisierung der Matrix $A$ wird die Zuordnung der Wörter des Wortvektors $v$  zu den Artikeln des Vektors $a$ in zwei Stufen zerlegt. \n",
    "\n",
    "$$\n",
    "f = H*v\n",
    "$$\n",
    "$$\n",
    "a = W*f \n",
    "$$\n",
    "\n",
    "In der ersten Stufe werden durch die Multiplikation von $v$ mit der Matrix $H$ die Wörter einem sogenannten Merkmalsvektor $f$ mit $m$ Elementen zugewiesen. In der zweiten Stufe werden durch die Multiplikation des Merkmalsvektor $f$ mit der Matrix $W$ die einzelnen Merkmale den Artikeln in $a$ zugeordnet. Die Matrix $H$ definiert also aus welchen Wörtern die Merkmale gebildet werden. Sie wird deshalb __Merkmalsmatrix__ genannt. Die Matrix $W$ hingegen beschreibt mit welchem Gewicht die einzelnen Merkmale in den verschiedenen Artikeln auftreten. Sie wird deshalb __Gewichtungsmatrix__ genannt.\n",
    "\n",
    "Daraus folgt: Wenn eine Faktorisierung der Matrix $A$ gefunden wird, dann werden damit auch relevante Merkmale, also die Themen, definiert, hinsichtlich derer die Artikel effizient kategorisiert werden. Durch die Matrixfaktorisierung wird eine __Merkmalsextraktion__ realisiert. \n",
    "\n",
    "### Berechnung der Matrixfaktoren\n",
    "\n",
    "Für die Berechnung der Faktoren wurde in [Lee, Algortihms for Non-negative Matrix Factorisation](http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf) eine iterative Methode vorgestellt, die derzeit wohl am häufigsten angewandt wird und auch in dieser Übung implementiert werden soll. Der Algorithmus besteht aus folgenden Schritten:\n",
    "* Gebe die zu faktorisierende Matrix $A$ ein. $r$ sei die Anzahl der Zeilen und $c$ die Anzahl der Spalten von $A$.\n",
    "* Wähle die Anzahl $m$ der Merkmale, mit $m<c$. _Tipp:_ Für $m$ sollte zunächst ein Wert im Bereich $15$ bis $30$ gewählt werden.\n",
    "* Lege eine $m \\times c$ Matrix $H$ an mit initial zufälligen Elementen (Anwendung der numpy Funktion _random.random()_)\n",
    "* Lege eine $r \\times m$ Matrix $W$ an mit initial zufälligen Elementen (Anwendung der numpy Funktion _random.random()_)\n",
    "* Wiederhole bis maximale Anzahl der Iteration erreicht oder Kosten $k$ unter vordefinierter Schwelle:\n",
    "\n",
    "\t* Berechne aktuelles Produkt $B=W*H$ und bereche die Kostenfunktion \n",
    "\t\t$$\n",
    "\t\t\tk=\\left\\| A - B \\right\\|^2 = \\sum\\limits_{i,j} \\left(A_{i,j} - B_{i,j}\\right)^2\n",
    "\t\t$$ \n",
    "\t* Anpassung der Matrix $H$ durch folgende Neuberechnung der Matrixelemente\n",
    "    \n",
    "\t\t$$\n",
    "\t\tH_{i,j} := H_{i,j} \\frac{(W^T*A)_{i,j}}{(W^T*W*H)_{i,j}}\n",
    "\t\t$$\n",
    "        \n",
    "\t* __Nach__ der Anpassung der Matrix $H$: Anpassung der Matrix $W$ durch folgende Neuberechnung der Matrixelemente\n",
    "    \n",
    "\t\t$$\n",
    "\t\tW_{l,i} := W_{l,i} \\frac{(A*H^T)_{l,i}}{(W*H*H^T)_{l,i}}\n",
    "\t\t$$\n",
    "\n",
    "In [Lee, Algortihms for Non-negative Matrix Factorisation](http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf) ist bewiesen, dass durch die o.g. Anpassungsroutinen die Kosten $k$ monoton abnehmen und in einem Minimum konvergieren. Der Algorithmus ist jedoch nicht optimal weil das gefundene Minimum ein lokales Minimum sein kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Vor dem Versuch zu klärende Fragen\n",
    " \n",
    " * Was versteht man unter Artikel/Wort-Matrix? Wie wird diese im aktuellen Versuch gebildet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Eine Artikel/Wort-Matrix besteht aus einem Vektor i für die Dokumente und einem Vektor j für die Worte.\n",
    "Dabei sind die Worte in mindestens einem Dokument enthalten.\n",
    "\n",
    "In diesem Versuch verwenden wir die Nicht-Negative Matrix Faktorisierung.\n",
    "Hierbei werden die Worte auf thematisch Relevante Worte reduziert.\n",
    "Dabei fallen Füllworte weg, und eine Gewichtung für bestimmte Keywords kann gelegt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wie multipliziert man die Matrix\n",
    "    $$\n",
    "    A= \\left( \\begin{array}{cccc}\n",
    "a_{00} & a_{01} & a_{02} & a_{03} \\\\ \n",
    "a_{10} & a_{11} & a_{12} & a_{13} \\\\ \n",
    "a_{20} & a_{21} & a_{22} & a_{23}\n",
    "\\end{array} \\right)\n",
    "    $$\n",
    "    mit dem Vektor  \n",
    "    $$\n",
    "    v=\\left( \\begin{array}{c}\n",
    "v_{0} \\\\ \n",
    "v_{1} \\\\ \n",
    "v_{2} \\\\ \n",
    "v_{3}\n",
    "\\end{array} \\right)\n",
    "    $$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Your markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Was versteht man im Kontext der NNMF unter\n",
    "    * Merkmalsmatrix\n",
    "    * Gewichtsmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Merkmalsmatrix\n",
    "Aus dem Skript, die Matrix H\n",
    "\n",
    "Beschreibt aus welchen Worten die Merkmale gebildet werden.\n",
    "Ein Merkmal ist hierbei, beispielsweise ein Topic. \n",
    "Jede zeile ist ein Topic, und jede Spalte ist ein Wort.\n",
    "Nun wird jeder Topic/Wort kombination ein Gewicht zugeordnet.\n",
    "Beispiel: Kochen: Salz 5, Auto 0\n",
    "\n",
    "#### Gewichtsmatrix\n",
    "\n",
    "Aus dem Skript, die Matrix W\n",
    "\n",
    "Beschreibt mit welchem Gewicht die Merkmale in den jeweiligen Artikeln auftreten.\n",
    "Jede Zeile ist ein Artikel und jede Spalte ein Merkmal.\n",
    "Jeder Artikel/Merkmal Kombination wird nun eine Gewichtung zugeordnet.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "* \"Wie Kochen unser leben bereichert\" : Kochen 5\n",
    "* \"Warum Autos noch nicht fliegen\" : Kochen 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wie werden in Numpy zwei Arrays (Typ numpy.array) \n",
    "\t* im Sinne der Matrixmultiplikation miteinander multipliziert?\n",
    "\t* elementweise multipliziert?\n",
    "* Wie wird die Transponierte eines Numpy-Arrays berechnet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "import feedparser\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from gensim import corpora, models\n",
    "import numpy as np\n",
    "\n",
    "# import newsfeatures as nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5]\n",
      " [14]\n",
      " [23]]\n",
      "[[7 8]\n",
      " [9 2]]\n",
      "[[7 8]\n",
      " [9 2]]\n",
      "[ 5 14 23]\n",
      "[[ 3  4  3]\n",
      " [ 4  0 12]]\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[0 3 6]\n",
      " [1 4 7]\n",
      " [2 5 8]]\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6]])\n",
      "array([[1, 4],\n",
      "       [2, 5],\n",
      "       [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "    x1 = np.matrix(\"0,1,2; 3,4,5; 6,7,8\")\n",
    "    x2 = np.matrix(\"0,1,2\")\n",
    "    x2t = x2.T\n",
    "    print x1*x2t\n",
    "\n",
    "\n",
    "# array mit .dot oder auf matrix casten\n",
    "    \n",
    "    x = np.array( ((3,2,1), (1,0,2)) )\n",
    "    y = np.array( ((1,2), (0,1), (4,0)) )\n",
    "    print np.dot(x,y)\n",
    "    print np.mat(x) * np.mat(y)\n",
    "\n",
    "\n",
    "# elementweise multipliziert\n",
    "\n",
    "    x = np.arange(9).reshape((3,3))\n",
    "    y = np.arange(3)\n",
    "    print np.dot(x,y)\n",
    "\n",
    "# elementweise ist default bei array multiplikation\n",
    "    \n",
    "    x = np.array( ((3,2,1), (1,0,2)) )\n",
    "    y = np.array( ((1,2,3), (4,5,6)) )\n",
    "    print x * y\n",
    "\n",
    "# Wie wird die Transponierte eines Numpy-Arrays berechnet?\n",
    "\n",
    "    xTest = np.arange(9).reshape((3,3))\n",
    "    xTrans = np.transpose(xTest)\n",
    "    print xTest\n",
    "    print xTrans\n",
    "\n",
    "# geht auch mit .T\n",
    "\n",
    "    x = np.array( ((1,2,3), (4,5,6)) )\n",
    "    pp.pprint(x)\n",
    "    pp.pprint(x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versuchsdurchführung\n",
    "Die in diesem Versuch einzubindenden Feeds sind in der unten stehenden Liste _feedlist_ definiert. Die aus dem vorigen Vesuch bereits bekannte Funktion _stripHTML()_ ist ebenfalls gegeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "feedlist=['http://feeds.reuters.com/reuters/topNews',\n",
    "          'http://feeds.reuters.com/reuters/businessNews',\n",
    "          'http://feeds.reuters.com/reuters/worldNews',\n",
    "          'http://feeds2.feedburner.com/time/world',\n",
    "          'http://feeds2.feedburner.com/time/business',\n",
    "          'http://feeds2.feedburner.com/time/politics',\n",
    "          'http://rss.cnn.com/rss/edition.rss',\n",
    "          'http://rss.cnn.com/rss/edition_world.rss',\n",
    "          'http://www.nytimes.com/services/xml/rss/nyt/GlobalHome.xml',\n",
    "          'http://feeds.nytimes.com/nyt/rss/Business',\n",
    "          'http://www.nytimes.com/services/xml/rss/nyt/World.xml',\n",
    "          'http://www.nytimes.com/services/xml/rss/nyt/Economy.xml'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripHTML(h):\n",
    "  p=''\n",
    "  s=0\n",
    "  for c in h:\n",
    "    if c=='<': s=1\n",
    "    elif c=='>':\n",
    "      s=0\n",
    "      p+=' '\n",
    "    elif s==0: p+=c\n",
    "  return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anlegen der Artikel/Wort-Matrix\n",
    "\n",
    "### Die Funktion _getarticlewords()_\n",
    "Schreiben Sie eine Funktion _getarticlewords()_, die folgende Elemente zurückgibt:\n",
    "\n",
    "* _allwords:_ ist ein Dictionary dessen Keys die Worte aller gesammelten Artikel sind. Der zu jedem Key gehörende Wert ist die Anzahl, wie oft das Wort insgesamt vorkommt.\n",
    "* _articlewords:_ ist eine Liste mit so vielen Elementen wie Artikel in der Sammlung sind. Jedes Listenelement ist ein Dictionary, welches die Worte des jeweiligen Artikels als Key enthält und als Wert die Worthäufigkeit.\n",
    "* _articletitles_ ist eine Liste mit so vielen Elementen wie Artikel in der Sammlung sind. Jedes Element ist der Artikeltitel als String.\n",
    "\n",
    "Für das Parsing der Feeds soll wieder das Modul _feedparser_ eingesetzt werden. Die zu einer Nachricht gehörenden Wörter sollen die Wörter des Elements _title_ und die Wörter des Elements _description_ sein (siehe voriger Versuch). Allerdings sollen hier nicht alle Wörter eingebunden werden, sondern wie im vorigen Versuch eine Methode _getwords()_ implementiert werden, welche nur die _relevanten_ Wörter zurückgibt. Die Frage welche Wörter relevant sind ist nicht eindeutig beantwortbar. Sie können sich hierzu eigene Antworten einfallen lassen. Auf jeden Fall sollten aber die Stopwörter ignoriert werden. Hierzu kann z.B. die Stopwortliste von NLTK angewandt werden.\n",
    "\n",
    "Nachdem alle relevanten Wörter aller Nachrichten gesammelt sind, sollte eine weitere Bereinigung stattfinden, die \n",
    "\n",
    "* alle Wörter, die weniger als 4 mal vorkommen\n",
    "* alle Wörter, die in mehr als 30% aller Dokumente vorkommen\n",
    "\n",
    "entfernt. \n",
    "\n",
    "Durch dieses Herausfiltern nicht relevanter Wörter kann es vorkommen, dass einzelne Artikel keine relevanten Wörter mehr enthalten. Diese Artikel sollen dann ganz ignoriert werden. D.h. unter anderem, dass diese Artikel auch nicht in _articlewords_ und _articletitles_ erscheinen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordList(doc):\n",
    "    words = str.split(doc.lower())\n",
    "    wordsStripped = [word.strip('().,:;!?-\"') for word in words]\n",
    "    words = [word for word in wordsStripped if 2 < len(word) < 20 and word not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "def getarticlewords(feedList):\n",
    "    allwords = {}\n",
    "    articlewords = []\n",
    "    articletitles = []\n",
    "    \n",
    "    for feed in feedlist:\n",
    "        print('*'*30)\n",
    "        print(feed)\n",
    "        f=feedparser.parse(feed)\n",
    "        for message in f.entries:\n",
    "            if re.match(r'\\S', message.title): \n",
    "                print(10*'-'+message.title+10*'-')\n",
    "                articletitles.append(message.title)\n",
    "                try:\n",
    "                    fulltext=stripHTML(message.title+' '+message.description)\n",
    "                except:\n",
    "                    try:\n",
    "                        fulltext=stripHTML(message.title+' '+message.summary)\n",
    "                    except:\n",
    "                        print('no description or summary for', message.title)\n",
    "                words = getWordList(fulltext)\n",
    "                docDict = {}\n",
    "                for word in words:\n",
    "                    if word in allwords.keys():\n",
    "                        allwords[word] = allwords[word] + 1\n",
    "                    else:\n",
    "                        allwords[word] = 1\n",
    "                    if word in docDict.keys():\n",
    "                        docDict[word] = docDict[word] + 1\n",
    "                    else:\n",
    "                        docDict[word] = 1\n",
    "                articlewords.append(docDict)\n",
    "    \n",
    "    nonrelevantwords = [word for word in allwords.keys() if allwords[word] < 4]\n",
    "    for word in allwords.keys():\n",
    "        if word not in nonrelevantwords:\n",
    "            counter = 0\n",
    "            for a in articlewords:\n",
    "                if word in a.keys():\n",
    "                    counter += 1\n",
    "            if counter / len(articletitles) > 0.3:\n",
    "                nonrelevantwords.append(word)\n",
    "    \n",
    "    for word in nonrelevantwords:\n",
    "        catchValue = allwords.pop(word)\n",
    "        for article in articlewords:\n",
    "            catchValue = article.pop(word, None)\n",
    "            \n",
    "    for article in articlewords:\n",
    "        if not article:\n",
    "            del articletitles[articlewords.index(article)]\n",
    "            articlewords.remove(article)\n",
    "        # try without this block\n",
    "        elif len(article) < 3:\n",
    "            for word in article.keys():\n",
    "                allwords[word] -= 1\n",
    "            articletitles[articlewords.index(article)] = None\n",
    "            articlewords[articlewords.index(article)] = None\n",
    "\n",
    "    articlewords = list(filter(None, articlewords))\n",
    "    articletitles = list(filter(None, articletitles))\n",
    "    return allwords, articlewords, articletitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "http://feeds.reuters.com/reuters/topNews\n",
      "----------U.S. judge sends ex-Trump campaign head Manafort to jail until trial----------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "descriptor 'split' requires a 'str' object but received a 'unicode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6322e004ddef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreturnValues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetarticlewords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeedlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mallwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturnValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0marticlewords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturnValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0marticletitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturnValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-000bcc34db96>\u001b[0m in \u001b[0;36mgetarticlewords\u001b[0;34m(feedList)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no description or summary for'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetWordList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mdocDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-000bcc34db96>\u001b[0m in \u001b[0;36mgetWordList\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetWordList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mwordsStripped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'().,:;!?-\"'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordsStripped\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: descriptor 'split' requires a 'str' object but received a 'unicode'"
     ]
    }
   ],
   "source": [
    "returnValues = getarticlewords(feedlist)\n",
    "allwords = returnValues[0]\n",
    "articlewords = returnValues[1]\n",
    "articletitles = returnValues[2]\n",
    "\n",
    "print(50*'*')\n",
    "for docDict in articlewords:\n",
    "    print(docDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Funktion _makematrix()_\n",
    "Schreiben Sie eine Funktion _makematrix()_, die aus dem Dictionary _allwords_ und der Liste _articlewords_ (vorige Aufgabe) die Artikel-/Wort-Matrix generiert. Die Einträge in der Matrix sollen die Häufigkeiten der Wörter im jeweiligen Dokument sein (term frequency tf). Die Artikel-/Wort-Matrix soll als 2-dimensionales Numpy Array angelegt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makematrix(allwords, articlewords, articletitles):\n",
    "    temp_articlewords = {}\n",
    "    for index, value in enumerate(articlewwords):\n",
    "        temp_articlewords[index] = value\n",
    "\n",
    "    articlewords = temp_articlewords\n",
    "\n",
    "    # Declaring Vars\n",
    "    wordvec = []\n",
    "    wordInArt = {}\n",
    "\n",
    "    # Removing words that have a overall Wordcount >= 4\n",
    "    trimmedV = {}\n",
    "    for word in allwords:\n",
    "        if allwords[word] >= 4:\n",
    "            trimmedV[word] = allwords[word]\n",
    "\n",
    "    # Removing words that appear > 30% in all Articles\n",
    "    #\n",
    "    # artP: Percent per Article occurence\n",
    "    # percentage: Percentage counting Value\n",
    "    # trimmedPercent: Copy of trimmedV since Python doesnt allow changing Dicts in a Loop\n",
    "    artP = (100 / float(len(articlewords)))\n",
    "    percentage = 0\n",
    "    trimmedPercent = trimmedV.copy()\n",
    "    for wordV in trimmedV:\n",
    "        for article in articlewords:\n",
    "            if articlewords[article].has_key(wordV):\n",
    "                percentage += artP\n",
    "        if percentage > 30:\n",
    "            trimmedPercent.pop(wordV)\n",
    "        percentage = 0\n",
    "\n",
    "    # Create Article/Word Matrix\n",
    "    #\n",
    "    # We Loop trough the articlewords for vector i\n",
    "    # We Loop trough trimmedPercent for vector j\n",
    "    awMatrix = {}\n",
    "    valueCount = 0\n",
    "    popArticleTitles = []\n",
    "    for article in articlewords:\n",
    "        awMatrix[article] = {}\n",
    "        valueCount = 0\n",
    "        for wordAW in trimmedPercent:\n",
    "            if wordAW in articlewords[article]:\n",
    "                awMatrix[article][wordAW] = articlewords[article][wordAW]\n",
    "                valueCount += 1\n",
    "            else:\n",
    "                awMatrix[article][wordAW] = 0\n",
    "\n",
    "        # Checking if the Article has only 0 values\n",
    "        # then pop the Artice out of the Dict\n",
    "        if valueCount == 0:\n",
    "            awMatrix.pop(article)\n",
    "            popArticleTitles.append(article)\n",
    "\n",
    "    # this makes sure that no articles are tried to pop without an existing index\n",
    "    for index in reversed(popArticleTitles):\n",
    "        articletitles.pop(index)\n",
    "\n",
    "\n",
    "    # Writing the wordvec and wordInArt Variables\n",
    "    # Note: This should give us an reference, so no Additional Space is wasted in RAM\n",
    "    # nicht tun! wordvec = trimmedPercent\n",
    "    wordInArt = awMatrix\n",
    "\n",
    "    # Creating Text File with Matrix\n",
    "    file = open('awMatrix.txt', 'w')\n",
    "    wordvecText = ''\n",
    "    # First Line consists of wordvec\n",
    "    for i, txtWord in enumerate(trimmedPercent):\n",
    "        if i != len(trimmedPercent) - 1:\n",
    "            wordvecText += txtWord + ','\n",
    "            wordvec.append(txtWord)\n",
    "        else:\n",
    "            wordvecText += txtWord + '\\n'\n",
    "\n",
    "    # Creating the Data from wordInArt Matrix\n",
    "    wordInArtText = ''\n",
    "    for txtArticle in awMatrix:\n",
    "        for i, txtData in enumerate(awMatrix[txtArticle]):\n",
    "            if i != len(awMatrix[txtArticle]) - 1:\n",
    "                wordInArtText += str(awMatrix[txtArticle][txtData]) + ','\n",
    "            else:\n",
    "                wordInArtText += str(awMatrix[txtArticle][txtData]) + '\\n'\n",
    "\n",
    "    # Writing to File\n",
    "    file.write(wordvecText)\n",
    "    file.write(wordInArtText)\n",
    "    file.close()\n",
    "\n",
    "    return (wordvec, wordInArt, articletitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the Article/Word Matrix as numpy.matrix Object\n",
    "def transformMatrix(awDict):\n",
    "    matrixList = []\n",
    "    # Iterating rough awDict and Converting Data into a nested List\n",
    "    for row in awDict:\n",
    "        rowList = []\n",
    "        if debug:\n",
    "            print(row)\n",
    "        for i, col in enumerate(awDict[row]):\n",
    "            rowList.append(awDict[row][col])\n",
    "        matrixList.append(rowList)\n",
    "    # Transforming nested List to an numpy Matrix\n",
    "    awNumpyMatrix = np.matrix(matrixList)\n",
    "\n",
    "    return awNumpyMatrix\n",
    "\n",
    "\n",
    "# A and B are of type numpy.matrix\n",
    "# returns the summed euclidean distance of the passed matrices\n",
    "def cost(A, B):\n",
    "    k = 0\n",
    "    # create iterators\n",
    "    iteratorA = A.flat\n",
    "    iteratorB = B.flat\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # iterate over all elements in both matrices\n",
    "            Aij = iteratorA.next()\n",
    "            Bij = iteratorB.next()\n",
    "            k += pow(Aij - Bij, 2)\n",
    "            # print \"Aij=%d | Bij=%d\" % (Aij, Bij)\n",
    "\n",
    "    except StopIteration:\n",
    "        pass  # needed because the iterator does not know if there are more elements coming\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getarticlewords() takes exactly 1 argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-37c7580e310c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mallwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticlewords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticletitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetarticlewords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"allwords:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\narticlewords:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticlewords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"articletitles:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticletitles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakematrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticlewords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticletitles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getarticlewords() takes exactly 1 argument (0 given)"
     ]
    }
   ],
   "source": [
    "allwords, articlewords, articletitles = getarticlewords()\n",
    "\n",
    "print \"allwords:\\n\", allwords, \"\\narticlewords:\\n\", articlewords, \"articletitles:\", articletitles\n",
    "\n",
    "result = makematrix(allwords, articlewords, articletitles)\n",
    "wordvec, wordInArt, articletitles = result\n",
    "print \"wordVe:\\n\", wordVec, \"\\nwordInArt:\\n\", wordInArt, \"\\narticletitles:\\n\", articletitles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Nicht Negative Matrix Faktorisierung\n",
    "Die Implementierung der NNMF ist entsprechend der Beschreibung im Theoriekapitel durchzuführen.\n",
    "\n",
    "* Implementieren Sie die Funktion _cost(A,B)_. Dieser Funktion werden zwei Numpy-Matrizen $A$ und $B$ übergeben. Zurück geliefert werden die nach oben angegebener Formel berechneten Kosten $k$. Diese Funktion wird von der im folgenden beschriebenen Funktion _nnmf(A,m,it)_ benutzt.\n",
    "* Implementieren Sie die Funktion __nnmf(A,m,it)__. In dieser Funktion soll der oben beschriebene Algorithmus für die Nicht-negative Matrix Faktorisierung ausgeführt werden. Der Funktion wird die zu faktorisierende Matrix $A$, die Anzahl der Merkmale $m$ und die Anzahl der Iterationen $it$ übergeben. Die Funktion gibt die gefundenen Faktoren $W$ und $H$ zurück. In jeder Iteration sollen mit der Funktion __cost(A,B)__ die Kosten berechnet werden. Sobald die Kostenabnahme pro 10 Iterationen kleiner als $2$ ist oder eine maximale Anzahl von Iterationen ($maxIt=200$) erreicht ist, soll der Algorithmus mit der Rückgabe der Faktoren $W$ und $H$ terminieren.     \n",
    "\n",
    "\n",
    "Tipp für die Implementierung elementweiser Operationen von Matrizen: Für elementweise Operationen müssen in Python/Numpy nicht alle Elemente über Schleifen explizit berechnet werden. Eine elementweise Anpassung aller Matrixelemente kann kompakt programmiert werden indem die beteiligten Matrizen für diese Operationen als Arrays implementiert werden. Sollen z.B. die beiden gleich großen Numpy Arrays $U$ und $V$ elementweise multipliziert werden, dann wäre der entsprechende Programmcode einfach _U*V_.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NNMF\n",
    "# parameters:\n",
    "#     A: non-negative Matrix\n",
    "#     m: count of merkmal\n",
    "#     it: number of iterations\n",
    "# returns: {\n",
    "#     H: Merkmalsmatrix\n",
    "#     W: Gewichtsmatrix\n",
    "# }\n",
    "def nnmf(A, m, it):\n",
    "    # debug = True\n",
    "    # get row count and column count of A\n",
    "    r, c = A.shape\n",
    "\n",
    "    # step 2:\n",
    "    ## assert that m < c, else: throw exception\n",
    "    if m >= c:\n",
    "        # throw Argument Error\n",
    "        print \"nnmf throws argument Error: m must be smaller than c (count of columns)\"\n",
    "        return\n",
    "\n",
    "    # step 3+4:\n",
    "    # initialize matrices H and W\n",
    "    H = np.matrix(np.random.randint(0, 5, (m, c)))  # 0 needs to be excluded\n",
    "    W = np.matrix(np.random.randint(0, 5, (r, m)))  # 0 needs to be excluded\n",
    "\n",
    "    # step 5:\n",
    "    while it > 0:\n",
    "        # calculate current product of H and W\n",
    "        # a)\n",
    "        B = W * H\n",
    "        k = cost(A, B)\n",
    "\n",
    "        if debug:\n",
    "            pp.pprint({'A': A, 'B': B})\n",
    "            print \"cost: %d\" % k\n",
    "\n",
    "        # break if desired matrix and factorized matrix are very similar\n",
    "        if k < 5:\n",
    "            break\n",
    "\n",
    "        # b) recalculate H\n",
    "        # Hij = Hij * (W_transposed * A)ij / (W_transposed * W * H)ij\n",
    "        temp1 = np.array(W.T * A)\n",
    "        temp2 = np.array(W.T * W * H)\n",
    "        H = np.matrix(np.array(H) * np.true_divide(temp1, temp2))  # normal divide floors the results\n",
    "        if debug:\n",
    "            pp.pprint({'H': H})\n",
    "\n",
    "        # c) recalculate W\n",
    "        # Wij = Wij * (A * H_transposed)ij / (W * H * H_transposed)ij\n",
    "        nextW = np.array(W) * np.true_divide(np.array(A * H.T),\n",
    "                                             np.array(W * H * H.T))  # normal divide floors the results\n",
    "        W = np.matrix(nextW)\n",
    "        if debug:\n",
    "            pp.pprint({'W': W})\n",
    "\n",
    "        it -= 1\n",
    "        if debug:\n",
    "            print \"current values with cost of %.3f: (%d more iterations)\" % (k, it)\n",
    "            pp.pprint({'W': W, 'H': H})\n",
    "            print \"result: cost=%.3f || %d more iterations\" % (k, it)\n",
    "            print \"-\" * 64\n",
    "\n",
    "    # return {'H': H, 'W': W}\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anzeige der Merkmale und der Gewichte\n",
    "\n",
    "Im vorigen Abschnitt wurde die Merkmalsmatrix $H$ und die Gewichtsmatrix $W$ berechnet. Diese Matrizen können natürlich am Bildschirm ausgegeben werden, was jedoch nicht besonders informativ ist. Aus den Matrizen können jedoch die Antworten für die folgenden interessanten Fragen berechnet werden:\n",
    "\n",
    "* In welchen Artikeln sind welche Merkmale stark vertreten?\n",
    "* Wie lassen sich die insgesamt $m$ Merkmale beschreiben, so dass aus dieser Merkmalsbeschreibung klar wird, welches Thema den Artikeln, in denen das Merkmal stark vertreten ist, behandelt wird? \n",
    " \n",
    "Die Antwort auf die erste Frage ergibt sich aus der Gewichtsmatrix $W$. Für die Beantwortung der zweiten Frage wird die Merkmalsmatrix $H$ herangezogen.\n",
    "\n",
    "\n",
    "\n",
    "### Beschreibung der Merkmale\n",
    "\n",
    "Die Merkmalsmatrix $H$ beschreibt, wie stark die Worte aus _wordvec_ in jedem Merkmal enthalten sind. Jede Zeile von $H$ gehört zu einem Merkmal, jede Spalte von $H$ gehört zu einem Wort in _wordvec_.\n",
    "\n",
    "Es bietet sich an jedes Merkmal einfach durch die $N=6$ Wörter aus _wordvec_ zu beschreiben, welche am stärksten in diesem Merkmal enthalten sind. Hierzu muss für jedes Merkmal die entsprechende Zeile in $H$ nach den $N=6$ größten Werten durchsucht bzw. geordnet werden. Die entsprechenden Spalten dieser Matrixelemente verweisen dann auf die $N=6$ wichtigsten Worte des Merkmals.\n",
    "\n",
    "Tipp für die Implementierung: Legen Sie für jedes Merkmal $i$ eine Liste an. Die Listenlänge ist durch die Anzahl der Worte in _wordvec_ (d.h. die Anzahl der Spalten in $H$) gegeben. Jedes Listenelement $j$ enthält selbst wieder 2 Elemente: An erster Stelle den entsprechenden Wert $H_{i,j}$ der Merkmalsmatrix, an der zweiten Stelle das $j.$-te Wort in _wordvec_. Nachdem die Liste angelegt ist, kann sie mit _listname.sort()_ in aufsteigender Reihenfolge sortiert werden. Die abnehmende Sortierung erhält man mit _listname.sort().reverse()_. Danach geben die $N=6$ ersten Listenelemente die für das Merkmal $i$ wichtigsten Worte an.\n",
    "\n",
    "   \n",
    "### Präsenz der Merkmale in den Artikeln\n",
    "\n",
    "Die Gewichtsmatrix $W$ beschreibt, wie stark die $m$ Merkmale in den Artikeln aus _articletitles_ enthalten sind. Jede Zeile von $W$ gehört zu einem Artikel, jede Spalte von $W$ gehört zu einem Merkmal.\n",
    "Die Berechnung der $M=2$ gewichtigsten Merkmale für jeden Artikel in _articletitles_ kann analog zu der oben beschriebenen Berechnung der $N=6$ wichtigsten Worte eines Merkmals berechnet werden.\n",
    "\n",
    "\n",
    "### Implementierung\n",
    "\n",
    "Implementieren Sie eine Funktion _showfeatures(w,h,titles,wordvec)_, welche wie oben beschrieben für jeden Artikel die $M=2$ wichtigsten Merkmale am Bildschirm ausgibt. Dabei soll jedes Merkmal durch die 6 wichtigsten Wörter dieses Merkmals angegeben werden. Siehe Beispielausgabe unten.  \n",
    "\n",
    "Übergabeparameter der Funktion sind die Merkmalsmatrix $H$, die Gewichtungsmatrix $W$, die Liste aller Artikeltitel _articletitles_ und die Liste aller Worte _wordvec_.\n",
    "\n",
    "\n",
    "Beispiel fuer Ausgabe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(13.54131155883748, 13, u'Putin vows payback after confirmation of Egypt plane bomb'),\n",
    "\n",
    "(2.2466669548146254, 9, u'Putin vows payback after confirmation of Egypt plane bomb')]\n",
    "\n",
    "----- ['plane', 'egypt', 'russia', 'month', 'killing', 'putin']\n",
    "\n",
    "----- ['airport', 'russian', 'crash', 'egypt', 'security', 'officials']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausgabe ist wie folgt zu interpretieren:\n",
    "* Für den Artikel _Putin vows payback after confirmation of Egypt plane bomb_ ist \n",
    "    * das wichtigste Merkmal durch die 6 Wörter _plane_, _egypt_, _russia_, _month_, _killing_, _putin_ definiert. Das Gewicht dieses Merkmals im Artikel ist 13.54\n",
    "    * das zweitwichtigste Merkmal durch die 6 Wörter _airport_, _russian_, _crash_, _egypt_, _security_, _officials_ definiert. Das Gewicht dieses Merkmals im Artikel ist 2.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showfeatures(W, H, titles, wordvec):\n",
    "    # Merkmale \n",
    "    sixImpWords = []\n",
    "    threeImpArt = []\n",
    "    rows, columns = H.shape\n",
    "    for i in range(rows):\n",
    "        wordlist = []\n",
    "        sortword = []\n",
    "        for j in range(len(wordvec)):\n",
    "            # for j in range(columns) :\n",
    "            wordlist.append([H[i, j], wordvec[j]])\n",
    "        sortword = sorted(wordlist, reverse=True)\n",
    "        sixW = []\n",
    "        for y in range(6):\n",
    "            sixW.append(sortword[y][1])\n",
    "        sixImpWords.append(sixW)\n",
    "\n",
    "        # Important articles \n",
    "    rows, columns = W.shape\n",
    "\n",
    "    for i in range(columns):\n",
    "        artlist = []\n",
    "        sortart = []\n",
    "        for j in range(rows):\n",
    "            artlist.append([W[j, i], titles[j]])\n",
    "        sortart = sorted(artlist, reverse=True)\n",
    "\n",
    "        threArt = []\n",
    "        for y in range(3):\n",
    "            threArt.append(sortart[y][1])\n",
    "        threeImpArt.append(threArt)\n",
    "\n",
    "    return sixImpWords, threeImpArt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben\n",
    "\n",
    "1. Analysieren Sie die berechneten Topics indem Sie sich überlegen ob die gefundenen 6 Wörter pro Topic wirklich Themen beschreiben.\n",
    "2. Verändern Sie die Parameter der NNMF (Anzahl der Topics $m$, Anzahl der Iterationen). Bei welcher Einstellung der Parameter erhalten Sie das für sie sinnvollste Resultat (sinnvolle Topics)?\n",
    "3. Wie kann die _getwords()_ Methode verbessert werden, so dass noch bedeutsamere Topics gefunden werden? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
